{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Experiment: Context Only\n",
    "\n",
    "This control tests predicting logP directly from pooled molecular features **without per-atom scalars**. Uses MPNN embeddings but predicts a single molecular logP value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src.mlp_regressor.mlp import ContextOnlyMLP\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load MPNN-processed atom embeddings from cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "CACHE_FILE = DATA_DIR / 'cache' / 'processed_molecules_cache.pkl'\n",
    "SPLITS_DIR = DATA_DIR / 'splits'\n",
    "\n",
    "# Load cached MPNN embeddings\n",
    "with open(CACHE_FILE, 'rb') as f:\n",
    "    cache = pickle.load(f)\n",
    "\n",
    "X_atoms = cache['X_atom_fps']\n",
    "atom_contribs = cache['atom_rdkit_score']\n",
    "mol_indexs = cache['mol_indexs']\n",
    "mol_data = cache['mol_data']\n",
    "\n",
    "print(f'MPNN embedding dim: {X_atoms.shape[1]}')\n",
    "print(f'Total atoms: {len(X_atoms)}, Total molecules: {len(mol_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load splits\n",
    "train_df = pd.read_csv(SPLITS_DIR / 'train.csv')\n",
    "val_df = pd.read_csv(SPLITS_DIR / 'val.csv')\n",
    "test_df = pd.read_csv(SPLITS_DIR / 'test.csv')\n",
    "\n",
    "train_mol_indices = train_df['mol_index'].values\n",
    "val_mol_indices = val_df['mol_index'].values\n",
    "test_mol_indices = test_df['mol_index'].values\n",
    "\n",
    "print(f'Train: {len(train_mol_indices)}, Val: {len(val_mol_indices)}, Test: {len(test_mol_indices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextOnlyDataset(Dataset):\n",
    "    \"\"\"Dataset that returns mean-pooled molecular features.\"\"\"\n",
    "    def __init__(self, X_atoms, mol_indexs, mol_data, mol_index_list):\n",
    "        self.X_atoms = X_atoms\n",
    "        self.mol_indexs = mol_indexs\n",
    "        self.mol_data = mol_data\n",
    "        self.mol_index_list = mol_index_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mol_index_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mol_index = self.mol_index_list[idx]\n",
    "        atom_mask = self.mol_indexs == mol_index\n",
    "        atom_features = torch.FloatTensor(self.X_atoms[atom_mask])\n",
    "        \n",
    "        return {\n",
    "            'atom_features': atom_features,\n",
    "            'exp_logp': torch.FloatTensor([self.mol_data[mol_index]['exp_logp']]),\n",
    "            'rdkit_logp': torch.FloatTensor([self.mol_data[mol_index]['rdkit_logp']]),\n",
    "            'mw': self.mol_data[mol_index]['mw'],\n",
    "            'mol_index': mol_index\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = ContextOnlyDataset(X_atoms, mol_indexs, mol_data, train_mol_indices)\n",
    "val_dataset = ContextOnlyDataset(X_atoms, mol_indexs, mol_data, val_mol_indices)\n",
    "test_dataset = ContextOnlyDataset(X_atoms, mol_indexs, mol_data, test_mol_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = X_atoms.shape[1]  # MPNN embeddings (44)\n",
    "HIDDEN_LAYERS = [40, 40, 32]\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model = ContextOnlyMLP(input_dim=INPUT_DIM, hidden_dims=HIDDEN_LAYERS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)\n",
    "print(f'\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(loader, desc='Training', leave=False):\n",
    "        for mol in batch:\n",
    "            atom_features = mol['atom_features'].to(device)\n",
    "            exp_logp = mol['exp_logp'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred_logp = model(atom_features)\n",
    "            loss = criterion(pred_logp.unsqueeze(0), exp_logp)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, targets, baselines, mws, mol_indices = [], [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Evaluating', leave=False):\n",
    "            for mol in batch:\n",
    "                atom_features = mol['atom_features'].to(device)\n",
    "                pred_logp = model(atom_features).item()\n",
    "                \n",
    "                preds.append(pred_logp)\n",
    "                targets.append(mol['exp_logp'].item())\n",
    "                baselines.append(mol['rdkit_logp'].item())\n",
    "                mws.append(mol['mw'])\n",
    "                mol_indices.append(mol['mol_index'])\n",
    "    return np.array(preds), np.array(targets), np.array(baselines), np.array(mws), np.array(mol_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_preds, val_targets, _, _, _ = evaluate(model, val_loader, device)\n",
    "    val_loss = mean_squared_error(val_targets, val_preds)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'context_only_best.pt')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val MSE = {val_loss:.4f}')\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f'Early stopping at epoch {epoch+1}')\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('context_only_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(train_losses, label='Train Loss')\n",
    "ax.plot(val_losses, label='Val MSE')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Curves - Context Only Model')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds, test_targets, test_baselines, test_mws, test_mol_indices = evaluate(model, test_loader, device)\n",
    "\n",
    "rmse_baseline = np.sqrt(mean_squared_error(test_targets, test_baselines))\n",
    "mae_baseline = mean_absolute_error(test_targets, test_baselines)\n",
    "rmse_model = np.sqrt(mean_squared_error(test_targets, test_preds))\n",
    "mae_model = mean_absolute_error(test_targets, test_preds)\n",
    "\n",
    "print('Test Set Performance')\n",
    "print('=' * 50)\n",
    "print(f'{\"Metric\":<20} | {\"Wildman-Crippen\":<15} | {\"Context Only\":<15}')\n",
    "print('-' * 50)\n",
    "print(f'{\"RMSE\":<20} | {rmse_baseline:<15.4f} | {rmse_model:<15.4f}')\n",
    "print(f'{\"MAE\":<20} | {mae_baseline:<15.4f} | {mae_model:<15.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "scatter = ax.scatter(test_targets, test_preds, alpha=0.5, s=30, \n",
    "                     c=np.abs(test_targets - test_preds), cmap='viridis', vmin=0, vmax=2)\n",
    "\n",
    "min_val = min(test_targets.min(), test_preds.min())\n",
    "max_val = max(test_targets.max(), test_preds.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "ax.fill_between([min_val, max_val], [min_val - 0.5, max_val - 0.5], \n",
    "                [min_val + 0.5, max_val + 0.5], alpha=0.2, color='red', label='Â±0.5 logP units')\n",
    "\n",
    "ax.set_xlabel('Experimental logP', fontsize=12)\n",
    "ax.set_ylabel('Model Predicted logP', fontsize=12)\n",
    "ax.set_title(f'Context Only Model\\nRMSE = {rmse_model:.3f}, MAE = {mae_model:.3f}', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Absolute Error', fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abs_errors = np.abs(test_preds - test_targets)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.hist(model_abs_errors, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "\n",
    "mean_error = np.mean(model_abs_errors)\n",
    "median_error = np.median(model_abs_errors)\n",
    "ax.axvline(mean_error, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_error:.3f}')\n",
    "ax.axvline(median_error, color='orange', linestyle='--', linewidth=2, label=f'Median: {median_error:.3f}')\n",
    "\n",
    "ax.set_xlabel('Absolute Error', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('Distribution of Context Only Model Errors', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "stats_text = f'N = {len(model_abs_errors)}\\n'\n",
    "stats_text += f'Mean = {mean_error:.3f}\\n'\n",
    "stats_text += f'Median = {median_error:.3f}\\n'\n",
    "stats_text += f'Std = {np.std(model_abs_errors):.3f}'\n",
    "ax.text(0.95, 0.95, stats_text, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The context-only model predicts logP directly from mean-pooled MPNN embeddings:\n",
    "- Uses message passing (molecular structure encoded)\n",
    "- No per-atom scalars (single molecular prediction)\n",
    "\n",
    "Compare with the full model to quantify the contribution of per-atom correction factors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logp_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
